# Risk Profile: Story 4.1

Date: 2026-01-11
Reviewer: Quinn (Test Architect)

## Executive Summary

- Total Risks Identified: 7
- Critical Risks: 0
- High Risks: 0
- Medium Risks: 2
- Low Risks: 3
- Minimal Risks: 2
- Risk Score: 76/100 (Moderate Risk)

**Overall Assessment:** This story has moderate complexity with performance-critical requirements and state synchronization concerns. The main risks center around meeting the <100ms calculation target and handling race conditions from rapid filter changes. No security or business-critical risks identified. All risks have mitigations specified in the story tasks.

## Risk Matrix

| Risk ID | Description | Probability | Impact | Score | Priority |
|---------|-------------|-------------|--------|-------|----------|
| PERF-001 | Core stats calculation exceeds 100ms target | Medium (2) | Medium (2) | 4 | Medium |
| TECH-001 | Race condition from rapid filter changes | Medium (2) | Medium (2) | 4 | Medium |
| DATA-001 | Empty filtered DataFrame crash/undefined | Low (1) | Medium (2) | 2 | Low |
| DATA-002 | Single row metrics edge case (std=None) | Medium (2) | Low (1) | 2 | Low |
| TECH-002 | Tab navigation dirty hash tracking failure | Low (1) | Medium (2) | 2 | Low |
| TECH-003 | Debounce timer resource leak on destroy | Low (1) | Low (1) | 1 | Minimal |
| TECH-004 | Signal connection multiplicity on reconnect | Low (1) | Low (1) | 1 | Minimal |

## Detailed Risk Register

### PERF-001: Core Stats Calculation Performance

**Score: 4 (Medium)**
**Probability**: Medium - Performance depends on dataset size; 10k rows typical, 100k rows worst case
**Impact**: Medium - Sluggish UI response degrades user experience; comparison ribbon updates delayed
**Mitigation**:
- Task 2 specifies splitting core stats (immediate) from equity curves (debounced)
- MetricsCalculator already optimized in Epic 3
- Task 9 includes explicit performance validation tests
- Debounce timer (300ms) prevents calculation spam
**Testing Focus**: Performance test with 10k and 100k rows (Task 9)
**Residual Risk**: Low - NumPy vectorized operations are fast; split architecture mitigates

### TECH-001: Race Condition from Rapid Filter Changes

**Score: 4 (Medium)**
**Probability**: Medium - User can rapidly adjust filter sliders; each change triggers signal
**Impact**: Medium - Stale metrics displayed; equity curves from old filter shown
**Mitigation**:
- 300ms debounce timer for equity curves prevents most race conditions
- Core stats recalculate each time (latest wins)
- Task 2 specifies `_schedule_equity_curve_calculation()` with debounce
- Signal `filtered_calculation_completed` fires only after final calculation
**Testing Focus**: Integration test for rapid filter changes (consider adding to Task 8)
**Residual Risk**: Low - Debounce pattern is well-established in UI frameworks

### DATA-001: Empty Filtered DataFrame Handling

**Score: 2 (Low)**
**Probability**: Low - Empty results are expected behavior for strict filters
**Impact**: Medium - Could crash if not handled; undefined state in comparison ribbon
**Mitigation**:
- Task 2 explicitly handles: "set filtered_metrics to `TradingMetrics.empty()`"
- Task 6 specifies unit test: "calculate with empty DataFrame returns empty metrics"
- `TradingMetrics.empty()` pattern established in Epic 3
**Testing Focus**: Unit test in test_metrics.py (Task 6)
**Residual Risk**: Minimal - Explicit handling specified

### DATA-002: Single Row Metrics Edge Case

**Score: 2 (Low)**
**Probability**: Medium - User could filter to a single trade
**Impact**: Low - Some metrics naturally undefined (std=None, streaks=1); acceptable behavior
**Mitigation**:
- Task 2 specifies handling: "calculate metrics (some will be None like std)"
- Task 6 specifies unit test: "single row returns valid metrics (some fields None)"
- UI should display em-dash for None values (established pattern)
**Testing Focus**: Unit test in test_metrics.py (Task 6)
**Residual Risk**: Minimal - Expected behavior documented

### TECH-002: Tab Navigation Hash Tracking

**Score: 2 (Low)**
**Probability**: Low - Hash comparison is deterministic operation
**Impact**: Medium - Redundant recalculations waste CPU; or stale data shown
**Mitigation**:
- Task 3 specifies `_filtered_df_hash: str | None` for dirty detection
- Standard pattern: compare hash on tab entry, recalculate if different
- Hash collision extremely unlikely with DataFrame content hash
**Testing Focus**: Integration test for tab navigation (Task 8)
**Residual Risk**: Minimal - Hash-based dirty tracking is proven pattern

### TECH-003: Debounce Timer Resource Leak

**Score: 1 (Minimal)**
**Probability**: Low - Qt QTimer cleanup is automatic on parent widget destroy
**Impact**: Low - Minor memory leak; timer fires to destroyed widget
**Mitigation**:
- Qt parent-child ownership handles cleanup
- Timer is single-shot, self-terminating
- Standard pattern used throughout application
**Testing Focus**: Not required - Qt framework handles
**Residual Risk**: None significant

### TECH-004: Signal Connection Multiplicity

**Score: 1 (Minimal)**
**Probability**: Low - Signals connected once in `__init__`
**Impact**: Low - Multiple identical calculations; minor performance waste
**Mitigation**:
- Connection happens in constructor, not in signal handlers
- Pattern follows existing code (Story 3.x)
**Testing Focus**: Code review verification
**Residual Risk**: None significant

## Risk Distribution

### By Category

- Technical (TECH): 4 risks (0 critical)
- Data (DATA): 2 risks (0 critical)
- Performance (PERF): 1 risk (0 critical)
- Security (SEC): 0 risks
- Business (BUS): 0 risks
- Operational (OPS): 0 risks

### By Component

- PnLStatsTab (calculation logic): 4 risks
- AppState (signals/storage): 2 risks
- CalculationStatusIndicator: 1 risk

## Risk-Based Testing Strategy

### Priority 1: Medium Risk Tests (PERF-001, TECH-001)

- Performance test: core stats < 100ms with 10k rows (Task 9)
- Performance test: verify 100k row dataset meets target (Task 9)
- Integration test: rapid filter changes produce consistent final state (Task 8)
- Integration test: debounce timer prevents calculation spam

### Priority 2: Low Risk Tests (DATA-001, DATA-002, TECH-002)

- Unit test: empty DataFrame returns `TradingMetrics.empty()` (Task 6)
- Unit test: single row returns valid metrics with None fields (Task 6)
- Integration test: tab navigation triggers recalculation when hash differs (Task 8)

### Priority 3: Minimal Risk Tests (TECH-003, TECH-004)

- Not requiring automated tests; code review sufficient

## Risk Acceptance Criteria

### Must Fix Before Production

- None (no critical or high risks)

### Can Deploy with Mitigation

- PERF-001: Performance validated with specified tests
- TECH-001: Debounce pattern in place

### Accepted Risks

- All 7 identified risks have mitigations specified in story tasks
- Residual risks are minimal with defensive coding patterns

## Monitoring Requirements

Post-deployment monitoring for:
- Performance: Track calculation times in debug logs
- User experience: Monitor for complaints about laggy filter response
- Errors: Log warnings when empty/single-row edge cases hit

## Risk Review Triggers

Review risk profile if:
- Performance complaints reported from users
- Dataset sizes exceed 100k rows become common
- Filter UI changes introduce new trigger patterns
- Memory usage issues surface

---

## Gate YAML Block

```yaml
# risk_summary (paste into gate file):
risk_summary:
  totals:
    critical: 0
    high: 0
    medium: 2
    low: 3
  highest:
    id: PERF-001
    score: 4
    title: "Core stats calculation exceeds 100ms target"
  recommendations:
    must_fix: []
    monitor:
      - "Track calculation performance in debug logs"
```

---

Risk profile: docs/qa/assessments/4.1-risk-20260111.md
