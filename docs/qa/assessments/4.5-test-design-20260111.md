# Test Design: Story 4.5 - Distribution Histograms

Date: 2026-01-11
Designer: Quinn (Test Architect)

## Test Strategy Overview

- **Total test scenarios:** 26
- **Unit tests:** 14 (54%)
- **Widget tests:** 10 (38%)
- **Integration tests:** 2 (8%)
- **Priority distribution:** P0: 1, P1: 17, P2: 6, P3: 1

## Test Scenarios by Acceptance Criteria

### AC1: Two histograms: Winner, Loser

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 4.5-UNIT-001 | Unit | P1 | `DistributionHistogram` instantiates without error | Core component availability |
| 4.5-INT-001 | Integration | P1 | Winner dialog opens from `view_histogram_clicked` signal | User journey verification |
| 4.5-INT-002 | Integration | P1 | Loser dialog opens from `view_histogram_clicked` signal | User journey verification |
| 4.5-WIDGET-001 | Widget | P1 | `HistogramDialog` displays correct title (Winner/Loser) | UI correctness |

**Test Implementation Notes:**
- Unit test: Simple instantiation check in `test_distribution_histogram.py`
- Integration tests: Verify signalâ†’dialog flow in `test_filter_workflow.py`
- Widget test: Check dialog title text matches card_type parameter

---

### AC2: Baseline bars (stellar-blue 50%) overlaid with filtered bars

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-002 | Unit | P1 | `set_baseline()` populates baseline BarGraphItem | Data binding | - |
| 4.5-UNIT-003 | Unit | P1 | `set_filtered()` populates filtered BarGraphItem | Data binding | - |
| 4.5-UNIT-004 | Unit | P2 | `set_baseline(None)` clears baseline bars | Edge case | DATA-001 |
| 4.5-UNIT-005 | Unit | P2 | `set_filtered(None)` clears filtered bars | Edge case | DATA-001 |
| 4.5-WIDGET-002 | Widget | P1 | Baseline bars use SIGNAL_BLUE at 50% alpha (128) | Visual specification | - |
| 4.5-WIDGET-003 | Widget | P1 | Filtered bars use SIGNAL_CYAN full opacity | Visual specification | - |
| 4.5-WIDGET-004 | Widget | P2 | Filtered bars overlay on top of baseline | Z-order rendering | TECH-001 |

**Test Implementation Notes:**
- Unit tests: Verify BarGraphItem data arrays after `set_*()` calls
- Widget tests: Inspect brush colors using `pg.mkBrush()` comparison
- Z-order test: Verify `plot_widget.items()` order

---

### AC3: Binning controls (auto, 0.5%, 1%, 2%, 5%)

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-006 | Unit | P0 | `_calculate_bins()` with auto uses Freedman-Diaconis | Algorithm correctness | TECH-002 |
| 4.5-UNIT-007 | Unit | P1 | `_calculate_bins()` with 0.5% bin width correct | Algorithm correctness | - |
| 4.5-UNIT-008 | Unit | P1 | `_calculate_bins()` with 1.0% bin width correct | Algorithm correctness | - |
| 4.5-UNIT-009 | Unit | P1 | `_calculate_bins()` with 2.0% bin width correct | Algorithm correctness | - |
| 4.5-UNIT-010 | Unit | P1 | `_calculate_bins()` with 5.0% bin width correct | Algorithm correctness | - |
| 4.5-UNIT-011 | Unit | P1 | `_calculate_bins()` handles empty data | Edge case | DATA-001 |
| 4.5-WIDGET-005 | Widget | P1 | Binning dropdown changes trigger rebinning | UI interaction | - |

**Test Implementation Notes:**
- Unit tests: Verify bin edges and counts for known input data
- Auto-binning test: Verify reasonable bin width for typical gain distributions
- Empty data test: Verify returns empty arrays without error
- Widget test: Change dropdown index, verify chart updates

---

### AC4: Mean/median reference lines

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 4.5-UNIT-012 | Unit | P1 | Mean/median lines update when data changes | Data binding |
| 4.5-UNIT-013 | Unit | P2 | Lines hidden when mean/median is None | Edge case |
| 4.5-WIDGET-006 | Widget | P1 | Mean line is amber dashed | Visual specification |
| 4.5-WIDGET-007 | Widget | P1 | Median line is white dotted | Visual specification |

**Test Implementation Notes:**
- Unit tests: Verify `InfiniteLine.setPos()` called with correct values
- Widget tests: Inspect pen style and color of line items

---

### AC5: Hover tooltips with bin counts

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 4.5-WIDGET-008 | Widget | P2 | Tooltip appears on bar hover | UI interaction |
| 4.5-WIDGET-009 | Widget | P2 | Tooltip shows bin range and count | Content correctness |
| 4.5-WIDGET-010 | Widget | P3 | Tooltip hides when mouse leaves chart | UI polish |

**Test Implementation Notes:**
- Use `qtbot.mouseMove()` to simulate hover events
- Verify `TextItem` visibility and text content

---

### AC6: "Show Baseline" toggle

| ID | Level | Priority | Test | Justification |
|----|-------|----------|------|---------------|
| 4.5-WIDGET-011 | Widget | P1 | Toggle unchecked hides baseline bars | UI interaction |
| 4.5-WIDGET-012 | Widget | P2 | Toggle re-checked shows baseline bars | UI interaction |

**Test Implementation Notes:**
- Toggle checkbox state with `qtbot.click()`
- Verify baseline BarGraphItem visibility

---

### Error Handling

| ID | Level | Priority | Test | Justification | Mitigates Risk |
|----|-------|----------|------|---------------|----------------|
| 4.5-UNIT-014 | Unit | P1 | `render_failed` signal emits on invalid data | Error resilience | DATA-001, DATA-002 |
| 4.5-UNIT-015 | Unit | P2 | `clear()` resets all data and bars | State management | - |

**Test Implementation Notes:**
- Use `qtbot.waitSignal()` to capture `render_failed` emission
- Verify `clear()` removes all bar data and hides lines

---

## Risk Coverage Matrix

| Risk ID | Risk Title | Mitigating Tests |
|---------|------------|------------------|
| TECH-001 | PyQtGraph bar overlay z-order | 4.5-WIDGET-004 |
| TECH-002 | Auto-binning edge cases | 4.5-UNIT-006 |
| DATA-001 | Empty/None data handling | 4.5-UNIT-004, 4.5-UNIT-005, 4.5-UNIT-011, 4.5-UNIT-014 |
| DATA-002 | NaN/Inf values | 4.5-UNIT-014 |

## Recommended Execution Order

1. **P0 Unit tests** (fail fast on algorithm issues)
   - 4.5-UNIT-006: Auto-binning algorithm

2. **P1 Unit tests** (core functionality)
   - 4.5-UNIT-001 through 4.5-UNIT-003, 4.5-UNIT-007 through 4.5-UNIT-012, 4.5-UNIT-014

3. **P1 Widget tests** (UI behavior)
   - 4.5-WIDGET-001 through 4.5-WIDGET-007, 4.5-WIDGET-011

4. **P1 Integration tests** (user journeys)
   - 4.5-INT-001, 4.5-INT-002

5. **P2 tests** (edge cases and polish)
   - 4.5-UNIT-004, 4.5-UNIT-005, 4.5-UNIT-013, 4.5-UNIT-015
   - 4.5-WIDGET-004, 4.5-WIDGET-008, 4.5-WIDGET-009, 4.5-WIDGET-012

6. **P3 tests** (nice-to-have)
   - 4.5-WIDGET-010

## Test File Locations

| File | Tests | Action |
|------|-------|--------|
| `tests/unit/test_distribution_histogram.py` | 4.5-UNIT-001 through 4.5-UNIT-015 | CREATE |
| `tests/widget/test_distribution_histogram.py` | 4.5-WIDGET-001 through 4.5-WIDGET-012 | CREATE |
| `tests/integration/test_filter_workflow.py` | 4.5-INT-001, 4.5-INT-002 | MODIFY |

## Quality Checklist

- [x] Every AC has test coverage
- [x] Test levels are appropriate (not over-testing)
- [x] No duplicate coverage across levels
- [x] Priorities align with business risk
- [x] Test IDs follow naming convention (4.5-LEVEL-SEQ)
- [x] Scenarios are atomic and independent
- [x] Risk mitigations addressed

## Coverage Gaps

None identified. All 6 acceptance criteria have appropriate test coverage.

## Key Principles Applied

- **Shift left**: 54% unit tests catch issues early
- **Risk-based**: DATA-001 edge cases have 4 dedicated tests
- **Efficient coverage**: Binning algorithm tested at unit level only (not duplicated in widget tests)
- **Maintainability**: Widget tests focus on behavior, not implementation details
- **Fast feedback**: P0/P1 tests run first in execution order
