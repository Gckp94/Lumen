# Risk Profile: Story 1.7 - Parquet Caching

Date: 2026-01-10
Reviewer: Quinn (Test Architect)

## Executive Summary

- **Total Risks Identified:** 7
- **Critical Risks:** 0
- **High Risks:** 0
- **Medium Risks:** 3
- **Low Risks:** 4
- **Risk Score:** 79/100 (Acceptable)

This is a relatively low-risk story focused on performance optimization through caching. The main concerns are around cache integrity, timing-based validation edge cases, and ensuring graceful degradation when cache operations fail.

## Risk Matrix

| Risk ID   | Description                              | Probability | Impact     | Score | Priority |
|-----------|------------------------------------------|-------------|------------|-------|----------|
| DATA-001  | Cache corruption undetected              | Low (1)     | High (3)   | 3     | Low      |
| DATA-002  | Cache-source timing race condition       | Medium (2)  | Medium (2) | 4     | Medium   |
| PERF-001  | Cache save blocking UI thread            | Medium (2)  | Medium (2) | 4     | Medium   |
| PERF-002  | Cache load exceeds 500ms target          | Low (1)     | Medium (2) | 2     | Low      |
| TECH-001  | MD5 hash collision for different files   | Low (1)     | Medium (2) | 2     | Low      |
| TECH-002  | Cache directory permission/creation fail | Low (1)     | Low (1)    | 1     | Minimal  |
| OPS-001   | Unbounded cache directory growth         | Medium (2)  | Low (1)    | 2     | Low      |

## Detailed Risk Register

### DATA-001: Cache Corruption Undetected

**Score: 3 (Low)**
**Probability**: Low - Parquet is a robust columnar format with built-in checksums
**Impact**: High - Corrupted data could propagate to analysis results silently

**Description:**
If a cache file becomes corrupted in a way that doesn't trigger Parquet read errors (e.g., valid format but wrong data), the user would receive incorrect data without warning.

**Mitigation:**
- Parquet's built-in integrity checks handle most corruption scenarios
- AC7 explicitly requires corrupt cache detection and fallback
- The implementation catches all exceptions during cache read and falls back to source
- Residual risk: Very rare edge cases where corruption produces valid but wrong data

**Testing Focus:**
- Test corrupt file handling (write garbage to .parquet file)
- Verify fallback to source load on any read error
- Verify cache file deletion on corruption

---

### DATA-002: Cache-Source Timing Race Condition

**Score: 4 (Medium)**
**Probability**: Medium - File modifications during app usage are common
**Impact**: Medium - User sees stale data until next modification

**Description:**
If the source file is modified between the cache validity check and the actual cache read, the user could receive stale cached data. Similarly, if modification time granularity is coarse, a quick edit might not invalidate the cache.

**Mitigation:**
- The validation uses mtime comparison which is file-system atomic
- Window of vulnerability is very small (microseconds)
- User can always force reload by modifying the source file again

**Testing Focus:**
- Test cache invalidation when source is modified
- Test boundary conditions around mtime comparison
- Verify cache miss when source is newer

---

### PERF-001: Cache Save Blocking UI Thread

**Score: 4 (Medium)**
**Probability**: Medium - Large DataFrames can take noticeable time to serialize
**Impact**: Medium - UI freeze during save degrades user experience

**Description:**
The cache save operation happens after successful load in the worker thread. However, if the worker emits `finished` signal before completing the save, the UI might become responsive while a potentially slow operation completes in the background. Conversely, if save happens before signal emission, large files could cause delays.

**Mitigation:**
- The implementation saves in the worker thread before emitting completion
- For large files (100k+ rows), save time should be < 1s (per story requirements)
- Non-critical operation - failure logged but doesn't affect functionality
- Consider async save if performance becomes issue

**Testing Focus:**
- Performance test with 100k row DataFrame
- Verify save completes within 1s target
- Verify UI remains responsive during large file operations

---

### PERF-002: Cache Load Exceeds 500ms Target

**Score: 2 (Low)**
**Probability**: Low - Parquet is highly optimized for read performance
**Impact**: Medium - Defeats purpose of caching if not faster than source

**Description:**
The AC6 requirement specifies cache load < 500ms vs source load 2-3s. While Parquet reads are typically 10-20x faster than Excel, edge cases (very wide DataFrames, many columns, slow disk) could exceed targets.

**Mitigation:**
- Parquet format is specifically designed for fast columnar reads
- Performance test included in Task 7 validates the target
- SSD storage typically ensures sub-100ms reads for 100k rows

**Testing Focus:**
- Explicit performance test measuring load time
- Test with 100k rows as baseline
- Mark test as @pytest.mark.slow

---

### TECH-001: MD5 Hash Collision

**Score: 2 (Low)**
**Probability**: Low - MD5 collision probability is ~2^64 for random inputs
**Impact**: Medium - Wrong cache served for different file/sheet combination

**Description:**
Two different file_path + sheet combinations could theoretically produce the same MD5 hash, causing cache collision.

**Mitigation:**
- MD5's 128-bit hash space makes accidental collisions astronomically unlikely
- For typical usage (dozens of files), collision probability is effectively zero
- Not a security context where intentional collision attacks matter

**Testing Focus:**
- Verify different sheets produce different cache keys
- Verify different files produce different cache keys
- No need to test for actual collisions (impractical)

---

### TECH-002: Cache Directory Permission/Creation Failure

**Score: 1 (Minimal)**
**Probability**: Low - Standard directory in project root
**Impact**: Low - Cache disabled, but app functions normally

**Description:**
The .lumen_cache directory might fail to create due to permissions, disk full, or other file system issues.

**Mitigation:**
- Directory created with `mkdir(exist_ok=True)` - idempotent
- Cache failures are logged but don't crash the app
- App continues to function, just without caching benefit

**Testing Focus:**
- Test directory creation on init
- Verify graceful handling of write failures

---

### OPS-001: Unbounded Cache Directory Growth

**Score: 2 (Low)**
**Probability**: Medium - Users may load many different files over time
**Impact**: Low - Disk space consumption, not functional impact

**Description:**
Each unique file/sheet combination creates a new cache file. Over time, the cache directory could grow to consume significant disk space, especially if users work with many different large files.

**Mitigation:**
- Cache files are significantly smaller than source Excel files
- User can manually delete .lumen_cache directory
- Future enhancement could add cache eviction policy

**Testing Focus:**
- Document cache location for user awareness
- Verify .gitignore excludes cache directory

---

## Risk Distribution

### By Category

| Category    | Count | Medium+ |
|-------------|-------|---------|
| Data        | 2     | 1       |
| Performance | 2     | 1       |
| Technical   | 2     | 0       |
| Operational | 1     | 0       |
| Security    | 0     | 0       |
| Business    | 0     | 0       |

### By Component

| Component       | Risks |
|-----------------|-------|
| CacheManager    | 5     |
| FileLoadWorker  | 2     |
| File System     | 2     |

## Risk-Based Testing Strategy

### Priority 1: Data Integrity Tests

- Corrupt cache file handling
- Cache invalidation on source modification
- Correct DataFrame returned from cache

### Priority 2: Performance Tests

- Cache load time < 500ms (100k rows)
- Cache save time < 1s (100k rows)
- UI responsiveness during operations

### Priority 3: Edge Case Tests

- Cache directory creation
- Different sheets produce different keys
- Graceful failure on file system errors

## Risk Acceptance Criteria

### Must Fix Before Production

- None - no critical or high risks identified

### Can Deploy with Mitigation

- DATA-002: Race condition window is acceptably small
- PERF-001: Worker thread design prevents UI blocking

### Accepted Risks

- TECH-001: MD5 collision probability is negligible for practical use
- OPS-001: Manual cache cleanup is acceptable for MVP

## Monitoring Requirements

Post-deployment monitoring for:

- Cache hit/miss ratio (logging provides this)
- Any cache corruption warnings in logs
- User feedback on load performance

## Risk Review Triggers

Review and update risk profile when:

- Caching extended to additional data types
- Cache eviction policy added
- Performance issues reported
- File system errors increase

---

## Gate YAML Block

```yaml
# risk_summary (paste into gate file):
risk_summary:
  totals:
    critical: 0
    high: 0
    medium: 3
    low: 4
  highest:
    id: DATA-002
    score: 4
    title: 'Cache-source timing race condition'
  recommendations:
    must_fix: []
    monitor:
      - 'Cache hit/miss ratio in logs'
      - 'Cache corruption warnings'
```

---

Risk profile: docs/qa/assessments/1.7-risk-20260110.md
